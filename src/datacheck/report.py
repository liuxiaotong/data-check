"""Quality report generation."""

import json
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

from datacheck.checker import CheckResult
from datacheck.rules import Severity


@dataclass
class QualityReport:
    """Generate human-readable quality reports."""

    result: CheckResult
    title: str = "æ•°æ®è´¨é‡æŠ¥å‘Š"

    def to_markdown(self) -> str:
        """Generate markdown report."""
        lines = [
            f"# {self.title}",
            "",
            f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            "",
            "---",
            "",
            "## æ¦‚è¦",
            "",
            f"| æŒ‡æ ‡ | æ•°å€¼ |",
            f"|------|------|",
            f"| æ€»æ ·æœ¬æ•° | {self.result.total_samples} |",
            f"| é€šè¿‡æ ·æœ¬ | {self.result.passed_samples} |",
            f"| å¤±è´¥æ ·æœ¬ | {self.result.failed_samples} |",
            f"| **é€šè¿‡ç‡** | **{self.result.pass_rate:.1%}** |",
            "",
        ]

        # Quality score visualization
        score = self.result.pass_rate * 100
        if score >= 90:
            grade = "ğŸŸ¢ ä¼˜ç§€"
        elif score >= 70:
            grade = "ğŸŸ¡ è‰¯å¥½"
        elif score >= 50:
            grade = "ğŸŸ  ä¸€èˆ¬"
        else:
            grade = "ğŸ”´ éœ€æ”¹è¿›"

        lines.extend([
            f"### è´¨é‡è¯„çº§: {grade} ({score:.0f}åˆ†)",
            "",
        ])

        # Issue summary
        if self.result.error_count or self.result.warning_count:
            lines.extend([
                "### é—®é¢˜ç»Ÿè®¡",
                "",
                f"| çº§åˆ« | æ•°é‡ |",
                f"|------|------|",
                f"| ğŸ”´ é”™è¯¯ | {self.result.error_count} |",
                f"| ğŸŸ¡ è­¦å‘Š | {self.result.warning_count} |",
                f"| ğŸ”µ æç¤º | {self.result.info_count} |",
                "",
            ])

        # Rule results
        if self.result.rule_results:
            lines.extend([
                "---",
                "",
                "## è§„åˆ™æ£€æŸ¥è¯¦æƒ…",
                "",
            ])

            for rule_id, rule_data in self.result.rule_results.items():
                severity = rule_data.get("severity", "warning")
                icon = {"error": "ğŸ”´", "warning": "ğŸŸ¡", "info": "ğŸ”µ"}.get(severity, "âšª")
                status = "âœ…" if rule_data["failed"] == 0 else "âŒ"

                lines.append(f"### {icon} {rule_data['name']} {status}")
                lines.append("")
                lines.append(f"- é€šè¿‡: {rule_data['passed']}")
                lines.append(f"- å¤±è´¥: {rule_data['failed']}")

                if rule_data["failed_samples"]:
                    lines.append(f"- å¤±è´¥æ ·æœ¬: {', '.join(rule_data['failed_samples'][:5])}")
                    if len(rule_data["failed_samples"]) > 5:
                        lines.append(f"  (è¿˜æœ‰ {len(rule_data['failed_samples']) - 5} ä¸ª...)")

                lines.append("")

        # Duplicates
        if self.result.duplicates:
            lines.extend([
                "---",
                "",
                "## é‡å¤æ£€æµ‹",
                "",
                f"å‘ç° **{len(self.result.duplicates)}** ç»„é‡å¤æ•°æ®:",
                "",
            ])

            for i, dup_group in enumerate(self.result.duplicates[:10], 1):
                lines.append(f"{i}. {', '.join(dup_group)}")

            if len(self.result.duplicates) > 10:
                lines.append(f"\n(è¿˜æœ‰ {len(self.result.duplicates) - 10} ç»„...)")

            lines.append("")

        # Distribution
        if self.result.distribution.get("fields"):
            lines.extend([
                "---",
                "",
                "## æ•°æ®åˆ†å¸ƒ",
                "",
            ])

            for field_name, field_stats in self.result.distribution["fields"].items():
                lines.append(f"### {field_name}")
                lines.append("")

                if "length_stats" in field_stats:
                    stats = field_stats["length_stats"]
                    lines.append(f"- é•¿åº¦: æœ€å° {stats['min']}, æœ€å¤§ {stats['max']}, å¹³å‡ {stats['avg']:.0f}")

                if "unique_ratio" in field_stats:
                    lines.append(f"- å”¯ä¸€å€¼æ¯”ä¾‹: {field_stats['unique_ratio']:.1%}")

                if "value_distribution" in field_stats:
                    lines.append("- å€¼åˆ†å¸ƒ:")
                    for val, count in list(field_stats["value_distribution"].items())[:5]:
                        lines.append(f"  - {val}: {count}")

                lines.append("")

        # Reference comparison
        if "reference_comparison" in self.result.distribution:
            comp = self.result.distribution["reference_comparison"]
            lines.extend([
                "---",
                "",
                "## ä¸å‚è€ƒæ•°æ®å¯¹æ¯”",
                "",
                f"æ ·æœ¬æ•°é‡: {comp['sample_count']} vs å‚è€ƒ: {comp['reference_count']}",
                "",
            ])

            for field_name, field_comp in comp.get("field_comparisons", {}).items():
                if "length_comparison" in field_comp:
                    lc = field_comp["length_comparison"]
                    lines.append(f"- **{field_name}** å¹³å‡é•¿åº¦: {lc['sample_avg']:.0f} vs {lc['reference_avg']:.0f} ({lc['diff_percent']:.1f}% å·®å¼‚)")

            lines.append("")

        # Failed samples
        if self.result.failed_sample_ids:
            lines.extend([
                "---",
                "",
                "## å¤±è´¥æ ·æœ¬åˆ—è¡¨",
                "",
                f"å…± {len(self.result.failed_sample_ids)} ä¸ªæ ·æœ¬æœªé€šè¿‡æ£€æŸ¥:",
                "",
            ])

            for sid in self.result.failed_sample_ids[:20]:
                lines.append(f"- {sid}")

            if len(self.result.failed_sample_ids) > 20:
                lines.append(f"\n(è¿˜æœ‰ {len(self.result.failed_sample_ids) - 20} ä¸ª...)")

        lines.extend([
            "",
            "---",
            "",
            "> æŠ¥å‘Šç”± DataCheck è‡ªåŠ¨ç”Ÿæˆ",
        ])

        return "\n".join(lines)

    def to_json(self) -> Dict[str, Any]:
        """Generate JSON report."""
        return {
            "title": self.title,
            "generated_at": datetime.now().isoformat(),
            "summary": {
                "total_samples": self.result.total_samples,
                "passed_samples": self.result.passed_samples,
                "failed_samples": self.result.failed_samples,
                "pass_rate": self.result.pass_rate,
                "error_count": self.result.error_count,
                "warning_count": self.result.warning_count,
                "info_count": self.result.info_count,
            },
            "rule_results": self.result.rule_results,
            "duplicates": self.result.duplicates,
            "distribution": self.result.distribution,
            "failed_sample_ids": self.result.failed_sample_ids,
        }

    def save(self, output_path: str, format: str = "markdown"):
        """Save report to file.

        Args:
            output_path: Output file path
            format: 'markdown' or 'json'
        """
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        if format == "json":
            with open(output_path, "w", encoding="utf-8") as f:
                json.dump(self.to_json(), f, indent=2, ensure_ascii=False)
        else:
            with open(output_path, "w", encoding="utf-8") as f:
                f.write(self.to_markdown())

    def print_summary(self):
        """Print summary to console."""
        score = self.result.pass_rate * 100
        if score >= 90:
            grade = "ğŸŸ¢ ä¼˜ç§€"
        elif score >= 70:
            grade = "ğŸŸ¡ è‰¯å¥½"
        elif score >= 50:
            grade = "ğŸŸ  ä¸€èˆ¬"
        else:
            grade = "ğŸ”´ éœ€æ”¹è¿›"

        print(f"\n{'='*50}")
        print(f"  æ•°æ®è´¨é‡æ£€æŸ¥ç»“æœ")
        print(f"{'='*50}")
        print(f"  æ€»æ ·æœ¬: {self.result.total_samples}")
        print(f"  é€šè¿‡: {self.result.passed_samples}")
        print(f"  å¤±è´¥: {self.result.failed_samples}")
        print(f"  é€šè¿‡ç‡: {self.result.pass_rate:.1%}")
        print(f"  è¯„çº§: {grade}")
        print(f"{'='*50}\n")
